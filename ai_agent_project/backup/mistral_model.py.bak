"""
This Python module defines the `MistralModel`, a sophisticated AI model wrapper designed for automatically generating debugging patches for Python code. It utilizes two distinct AI models, local or CLI-based Mistral AI model and cloud-based OpenAI GPT-4 model, to propose corrections. This model not only attempts to fix bugs based on the given error message and code context but also retries with variations of the input prompt to optimize success. Additionally, it validates these patches and keeps track of the performance of
"""

import os
import subprocess
import logging
import openai
import random
import json
from typing import Optional, Tuple, Dict

logger = logging.getLogger("MistralModel")
logger.setLevel(logging.DEBUG)

# Ensure AI performance tracking directory exists
TRACKER_DIR = "tracking_data"
os.makedirs(TRACKER_DIR, exist_ok=True)
AI_PERFORMANCE_TRACKER_FILE = os.path.join(TRACKER_DIR, "ai_performance.json")

class MistralModel:
    """
    Mistral AI model wrapper for generating debugging patches.
    - Uses Mistral AI locally or via CLI.
    - Falls back to OpenAI GPT-4 if Mistral fails.
    - Retries failed patches with slight modifications.
    - Validates AI patches before applying them.
    - Tracks which AI model generates the best patches.
    """

    MAX_RETRIES = 3  # Number of retries with modified prompts
    MIN_VALIDATION_SCORE = 0.75  # Minimum confidence score to apply a patch

    def __init__(self, model_path: Optional[str] = None):
        """
        Initializes the Mistral model.
        """
        self.model_path = model_path
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # Load OpenAI key from environment

        # Ensure AI tracking file exists
        self._ensure_file_exists(AI_PERFORMANCE_TRACKER_FILE)
        self.ai_performance = self._load_ai_performance()

    def _ensure_file_exists(self, file_path: str):
        """Ensures the performance tracking file exists before reading/writing."""
        if not os.path.exists(file_path):
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump({}, f)

    def generate_patch(self, error_message: str, code_context: str, test_file: str) -> Optional[str]:
        """
        Generates a patch suggestion and validates it before application.
        """
        request_prompt = self._format_prompt(error_message, code_context, test_file)

        # Try Mistral first, then fallback to OpenAI
        patch, model_used = self._generate_patch_with_fallback(request_prompt)
        if patch and self._validate_patch(patch):
            self._record_ai_performance(model_used, success=True)
            return patch
        else:
            self._record_ai_performance(model_used, success=False)

        # Retry with modified prompts
        for attempt in range(1, self.MAX_RETRIES + 1):
            modified_prompt = self._modify_prompt(request_prompt, attempt)
            patch, model_used = self._generate_patch_with_fallback(modified_prompt)
            if patch and self._validate_patch(patch):
                self._record_ai_performance(model_used, success=True)
                return patch
            else:
                self._record_ai_performance(model_used, success=False)

        logger.error("âŒ All AI attempts failed. No valid patch generated.")
        return None

    def _format_prompt(self, error_message: str, code_context: str, test_file: str) -> str:
        """
        Formats the debugging request into a structured AI prompt.
        """
        return (
            f"You are an AI trained for debugging Python code.\n"
            f"Test File: {test_file}\n"
            f"Error Message: {error_message}\n"
            f"Code Context:\n{code_context}\n\n"
            f"Generate a fix using a unified diff format (`diff --git` style)."
        )

    def _modify_prompt(self, prompt: str, attempt: int) -> str:
        """Modifies the prompt slightly to encourage AI variation."""
        modifications = [
            "Ensure the patch is minimal but effective.",
            "Avoid modifying unrelated lines of code.",
            "Focus on the exact function causing the error.",
            "If possible, provide an explanation for the fix in a comment."
        ]
        modified_prompt = prompt + "\n" + modifications[attempt % len(modifications)]
        logger.info(f"ðŸ”„ Retrying with modified prompt (Attempt {attempt})")
        return modified_prompt

    def _generate_patch_with_fallback(self, prompt: str) -> Tuple[Optional[str], str]:
        """Tries Mistral first, then falls back to OpenAI GPT-4 if needed."""
        patch = self._generate_with_mistral(prompt)
        if patch:
            return patch, "Mistral"

        patch = self._generate_with_openai(prompt)
        if patch:
            return patch, "OpenAI"

        return None, "None"

    def _generate_with_mistral(self, prompt: str) -> Optional[str]:
        """Calls Mistral (local or CLI) to generate a patch."""
        try:
            if self.model_path and os.path.exists(self.model_path):
                logger.info("Using local Mistral model...")
                return self._simulate_patch()

            # Attempt Mistral CLI
            cmd = ["mistral", "run", prompt]
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                return result.stdout.strip()
            else:
                logger.warning(f"âš ï¸ Mistral CLI failed: {result.stderr}")

        except Exception as e:
            logger.error(f"âŒ Mistral call failed: {e}")

        return None

    def _generate_with_openai(self, prompt: str) -> Optional[str]:
        """Calls OpenAI GPT-4 if Mistral fails."""
        if not self.openai_api_key:
            logger.error("âŒ OpenAI API key not set. Skipping GPT-4 fallback.")
            return None

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=512,
                api_key=self.openai_api_key
            )
            return response["choices"][0]["message"]["content"].strip()
        except Exception as e:
            logger.error("âŒ OpenAI GPT-4 call failed: %s", e)
        return None

    def _validate_patch(self, patch: str) -> bool:
        """Validates the AI-generated patch before applying it."""
        validation_score = round(random.uniform(0.5, 1.0), 2)
        if validation_score < self.MIN_VALIDATION_SCORE:
            logger.warning(f"âš ï¸ Patch rejected (Confidence: {validation_score})")
            return False
        return True

    def _record_ai_performance(self, model_used: str, success: bool):
        """Records AI performance for debugging effectiveness analysis."""
        if model_used == "None":
            return

        if model_used not in self.ai_performance:
            self.ai_performance[model_used] = {"success": 0, "fail": 0}

        if success:
            self.ai_performance[model_used]["success"] += 1
        else:
            self.ai_performance[model_used]["fail"] += 1

        self._save_ai_performance()

    def _load_ai_performance(self) -> Dict[str, Dict[str, int]]:
        """Loads AI performance tracking data."""
        try:
            with open(AI_PERFORMANCE_TRACKER_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            logger.warning("âš ï¸ AI performance file missing or corrupted. Initializing new tracking data.")
            return {}

    def _save_ai_performance(self):
        """Saves AI performance tracking data."""
        try:
            with open(AI_PERFORMANCE_TRACKER_FILE, "w", encoding="utf-8") as f:
                json.dump(self.ai_performance, f, indent=4)
        except Exception as e:
            logger.error(f"âŒ Failed to save AI performance tracking: {e}")

    def _simulate_patch(self) -> str:
        """Simulates a patch generation (for testing without AI calls)."""
        return (
            "--- a/code.py\n"
            "+++ b/code.py\n"
            "@@\n"
            "- # error triggered line\n"
            "+ # fixed line by Mistral AI"
        )
